# bitsofcotton/p1
Generic predictor that completely depends on data itself but doesn't win good randoms. This suppose original data have conserved value with the meaning of inner product.  
This is the better hypothesis because any taylor series can described as inner product, and, recursive predictions are also be in taylor series, lagrange multiplier, and, orthogonal variable x and y, their taylor series are in them with same meaning (which converges). And, if there's a triangular series like wavelet transform like fourier transform, and, their linear operations, also they are in this form. And, if the original stream is uncontinuous at all, it relates {(-1)^k} stream multiplication with subtracting cont. . It trivialy in this form. And, some strategic copycats also in this form.

# How to use:
    P1B<double> p(40, 20);
    xnext = p.next(x);
    ...

# How to use (command line):
    ./p1 <variable range> <status range> < data.txt

# Tips
If P1 class lasterr has larger absolute value than minimum change, this is useless for the problem nor unreliable for them.
If status length is not enough, edge clear change will come with suddenly. This is observable by each P1::fvec inner product cosine value.  
And, if the status length is enough, vanish can be used to drill the conserved value, otherwise, edge clear catastrophy can destroy the advantage.
